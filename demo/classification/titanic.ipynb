{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "titanic_df = pd.read_csv('titanic_data/data.csv')\n",
    "titanic_df['Survived'] = titanic_df['Survived'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO: \u001b[0mAnalyzer initialized. Shapes of train, test DataFrames: \u001b[93m(712, 12)\u001b[0m, \u001b[93m(179, 12)\u001b[0m. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================\n",
       "\u001b[1mtitanic\u001b[0m \n",
       "----------------------------------------------------------------------------------------\n",
       "\u001b[1mTrain shape: \u001b[0m\u001b[93m(712, 12)\u001b[0m                      \u001b[1mTest shape: \u001b[0m\u001b[93m(179, 12)\u001b[0m                       \n",
       "----------------------------------------------------------------------------------------\n",
       "\u001b[1mCategorical variables:\u001b[0m\n",
       "  \u001b[95m'Survived', \u001b[0m\u001b[95m'Name', \u001b[0m\u001b[95m'Sex', \u001b[0m\u001b[95m'Ticket', \u001b[0m\u001b[95m'Cabin', \u001b[0m\u001b[95m'Embarked'\u001b[0m \n",
       "                                                                                        \n",
       "\u001b[1mNumeric variables:\u001b[0m\n",
       "  \u001b[95m'PassengerId', \u001b[0m\u001b[95m'Pclass', \u001b[0m\u001b[95m'Age', \u001b[0m\u001b[95m'SibSp', \u001b[0m\u001b[95m'Parch', \u001b[0m\u001b[95m'Fare'\u001b[0m \n",
       "========================================================================================"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabularmagic as tm\n",
    "analyzer = tm.Analyzer(titanic_df, test_size=0.2, name='titanic')\n",
    "analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO: \u001b[0mEvaluating model LinearC(no_penalty). \n",
      "\u001b[91mWARN: \u001b[0mTrain data: dropped 140 rows with missing values out of a total of 712 rows. \n",
      "\u001b[93mPROG: \u001b[0mFitting LinearC(no_penalty). Search method: GridSearchCV (1 fits per fold, 5 total \n",
      "      fits). \n",
      "\u001b[93mPROG: \u001b[0mOptimal threshold set for LinearC(no_penalty) via F1 score. \n",
      "\u001b[91mWARN: \u001b[0mTest data: dropped 37 rows with missing values out of a total of 179 rows. \n",
      "\u001b[92mINFO: \u001b[0mSuccessfully evaluated model LinearC(no_penalty). \n",
      "\u001b[92mINFO: \u001b[0mEvaluating model LinearC(l1). \n",
      "\u001b[91mWARN: \u001b[0mTrain data: dropped 140 rows with missing values out of a total of 712 rows. \n",
      "\u001b[93mPROG: \u001b[0mFitting LinearC(l1). Search method: OptunaSearchCV (100 trials). \n",
      "\u001b[93mPROG: \u001b[0mOptimal threshold set for LinearC(l1) via F1 score. \n",
      "\u001b[91mWARN: \u001b[0mTest data: dropped 37 rows with missing values out of a total of 179 rows. \n",
      "\u001b[92mINFO: \u001b[0mSuccessfully evaluated model LinearC(l1). \n",
      "\u001b[92mINFO: \u001b[0mEvaluating model LinearC(l2). \n",
      "\u001b[91mWARN: \u001b[0mTrain data: dropped 140 rows with missing values out of a total of 712 rows. \n",
      "\u001b[93mPROG: \u001b[0mFitting LinearC(l2). Search method: OptunaSearchCV (100 trials). \n",
      "\u001b[93mPROG: \u001b[0mOptimal threshold set for LinearC(l2) via F1 score. \n",
      "\u001b[91mWARN: \u001b[0mTest data: dropped 37 rows with missing values out of a total of 179 rows. \n",
      "\u001b[92mINFO: \u001b[0mSuccessfully evaluated model LinearC(l2). \n",
      "\u001b[92mINFO: \u001b[0mEvaluating model TreeEnsembleC(random_forest). \n",
      "\u001b[91mWARN: \u001b[0mTrain data: dropped 140 rows with missing values out of a total of 712 rows. \n",
      "\u001b[93mPROG: \u001b[0mFitting TreeEnsembleC(random_forest). Search method: OptunaSearchCV (10 trials). \n",
      "\u001b[93mPROG: \u001b[0mOptimal threshold set for TreeEnsembleC(random_forest) via F1 score. \n",
      "\u001b[91mWARN: \u001b[0mTest data: dropped 37 rows with missing values out of a total of 179 rows. \n",
      "\u001b[92mINFO: \u001b[0mSuccessfully evaluated model TreeEnsembleC(random_forest). \n"
     ]
    }
   ],
   "source": [
    "report = analyzer.classify(\n",
    "    models=[\n",
    "        tm.ml.LinearC('no_penalty'),\n",
    "        tm.ml.LinearC('l1'),\n",
    "        tm.ml.LinearC('l2'),\n",
    "        tm.ml.TreeEnsembleC('random_forest', n_trials=10)\n",
    "    ],\n",
    "    target='Survived',\n",
    "    predictors=[\n",
    "        'Pclass',\n",
    "        'Sex',\n",
    "        'Fare',\n",
    "        'Age'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearC(no_penalty)</th>\n",
       "      <th>LinearC(l1)</th>\n",
       "      <th>LinearC(l2)</th>\n",
       "      <th>TreeEnsembleC(random_forest)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.838028</td>\n",
       "      <td>0.823944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.80916</td>\n",
       "      <td>0.80303</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.774775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.741379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.891626</td>\n",
       "      <td>0.889368</td>\n",
       "      <td>0.899425</td>\n",
       "      <td>0.887726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_obs</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LinearC(no_penalty) LinearC(l1) LinearC(l2)  \\\n",
       "Statistic                                               \n",
       "accuracy             0.823944    0.816901    0.838028   \n",
       "f1                    0.80916     0.80303    0.809917   \n",
       "precision            0.726027    0.716216    0.777778   \n",
       "recall               0.913793    0.913793    0.844828   \n",
       "roc_auc              0.891626    0.889368    0.899425   \n",
       "n_obs                     142         142         142   \n",
       "\n",
       "          TreeEnsembleC(random_forest)  \n",
       "Statistic                               \n",
       "accuracy                      0.823944  \n",
       "f1                            0.774775  \n",
       "precision                     0.811321  \n",
       "recall                        0.741379  \n",
       "roc_auc                       0.887726  \n",
       "n_obs                              142  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abs Coefs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male_yn(Sex)</th>\n",
       "      <td>2.477569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.085313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.027608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Abs Coefs\n",
       "Feature                \n",
       "male_yn(Sex)   2.477569\n",
       "Pclass         1.085313\n",
       "Fare           0.001015\n",
       "Age            0.027608"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.feature_importance('LinearC(no_penalty)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWARN: \u001b[0mTrain data: dropped 140 rows with missing values out of a total of 712 rows. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m glm_report \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mglm(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     predictors\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/projects/TabularMagic/demo/classification/../../tabularmagic/_src/utils/helpers.py:68\u001b[0m, in \u001b[0;36mensure_arg_list_uniqueness.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             seen\u001b[38;5;241m.\u001b[39madd(item)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# If all checks pass, call the original function\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/projects/TabularMagic/demo/classification/../../tabularmagic/_src/analyzer.py:297\u001b[0m, in \u001b[0;36mAnalyzer.glm\u001b[0;34m(self, family, target, predictors, formula)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PoissonRegressionReport(\n\u001b[1;32m    294\u001b[0m         PoissonLinearModel(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datahandler, target, predictors\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinomialRegressionReport(\n\u001b[1;32m    298\u001b[0m         BinomialLinearModel(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datahandler, target, predictors\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NegativeBinomialRegressionReport(\n\u001b[1;32m    302\u001b[0m         NegativeBinomialLinearModel(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datahandler, target, predictors\n\u001b[1;32m    303\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/projects/TabularMagic/demo/classification/../../tabularmagic/_src/linear/reports/binomialglmreg.py:741\u001b[0m, in \u001b[0;36mBinomialRegressionReport.__init__\u001b[0;34m(self, model, datahandler, target, predictors)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataemitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datahandler\u001b[38;5;241m.\u001b[39mtrain_test_emitter(target, predictors)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mspecify_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataemitter)\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_report \u001b[38;5;241m=\u001b[39m SingleDatasetBinRegReport(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/TabularMagic/demo/classification/../../tabularmagic/_src/linear/binomialglm.py:88\u001b[0m, in \u001b[0;36mBinomialLinearModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataemitter\u001b[38;5;241m.\u001b[39memit_train_Xy()\n\u001b[1;32m     86\u001b[0m X_train \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_train)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mGLM(\n\u001b[1;32m     89\u001b[0m     y_train,\n\u001b[1;32m     90\u001b[0m     X_train,\n\u001b[1;32m     91\u001b[0m     family\u001b[38;5;241m=\u001b[39msm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mBinomial(link\u001b[38;5;241m=\u001b[39msm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mlinks\u001b[38;5;241m.\u001b[39mLogit()),\n\u001b[1;32m     92\u001b[0m )\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHC3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m y_pred_train: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mpredict(exog\u001b[38;5;241m=\u001b[39mX_train)\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     96\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataemitter\u001b[38;5;241m.\u001b[39memit_test_Xy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/genmod/generalized_linear_model.py:325\u001b[0m, in \u001b[0;36mGLM.__init__\u001b[0;34m(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights \u001b[38;5;241m=\u001b[39m freq_weights\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights \u001b[38;5;241m=\u001b[39m var_weights\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28msuper\u001b[39m(GLM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[1;32m    326\u001b[0m                           offset\u001b[38;5;241m=\u001b[39moffset, exposure\u001b[38;5;241m=\u001b[39mexposure,\n\u001b[1;32m    327\u001b[0m                           freq_weights\u001b[38;5;241m=\u001b[39mfreq_weights,\n\u001b[1;32m    328\u001b[0m                           var_weights\u001b[38;5;241m=\u001b[39mvar_weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_inputs(family, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog,\n\u001b[1;32m    330\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[1;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(PandasData, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "glm_report = analyzer.glm(\n",
    "    'binomial',\n",
    "    target='Survived',\n",
    "    predictors=[\n",
    "        'Pclass',\n",
    "        'Sex',\n",
    "        'Fare',\n",
    "        'Age'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Survived</td>     <th>  No. Observations:  </th>  <td>   572</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -267.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 04 Aug 2024</td> <th>  Deviance:          </th> <td>  534.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>06:10:40</td>     <th>  Pearson chi2:      </th>  <td>  595.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3404</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    4.3005</td> <td>    0.602</td> <td>    7.147</td> <td> 0.000</td> <td>    3.121</td> <td>    5.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male_yn(Sex)</th> <td>   -2.4775</td> <td>    0.220</td> <td>  -11.276</td> <td> 0.000</td> <td>   -2.908</td> <td>   -2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>       <td>   -1.0853</td> <td>    0.174</td> <td>   -6.234</td> <td> 0.000</td> <td>   -1.427</td> <td>   -0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>         <td>    0.0010</td> <td>    0.002</td> <td>    0.502</td> <td> 0.616</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>          <td>   -0.0276</td> <td>    0.009</td> <td>   -3.182</td> <td> 0.001</td> <td>   -0.045</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     Survived     & \\textbf{  No. Observations:  } &      572    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      567    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -267.21   \\\\\n",
       "\\textbf{Date:}            & Sun, 04 Aug 2024 & \\textbf{  Deviance:          } &    534.42   \\\\\n",
       "\\textbf{Time:}            &     06:10:40     & \\textbf{  Pearson chi2:      } &     595.    \\\\\n",
       "\\textbf{No. Iterations:}  &        5         & \\textbf{  Pseudo R-squ. (CS):} &   0.3404    \\\\\n",
       "\\textbf{Covariance Type:} &       HC3        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}         &       4.3005  &        0.602     &     7.147  &         0.000        &        3.121    &        5.480     \\\\\n",
       "\\textbf{male\\_yn(Sex)} &      -2.4775  &        0.220     &   -11.276  &         0.000        &       -2.908    &       -2.047     \\\\\n",
       "\\textbf{Pclass}        &      -1.0853  &        0.174     &    -6.234  &         0.000        &       -1.427    &       -0.744     \\\\\n",
       "\\textbf{Fare}          &       0.0010  &        0.002     &     0.502  &         0.616        &       -0.003    &        0.005     \\\\\n",
       "\\textbf{Age}           &      -0.0276  &        0.009     &    -3.182  &         0.001        &       -0.045    &       -0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  572\n",
       "Model:                            GLM   Df Residuals:                      567\n",
       "Model Family:                Binomial   Df Model:                            4\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -267.21\n",
       "Date:                Sun, 04 Aug 2024   Deviance:                       534.42\n",
       "Time:                        06:10:40   Pearson chi2:                     595.\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):             0.3404\n",
       "Covariance Type:                  HC3                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            4.3005      0.602      7.147      0.000       3.121       5.480\n",
       "male_yn(Sex)    -2.4775      0.220    -11.276      0.000      -2.908      -2.047\n",
       "Pclass          -1.0853      0.174     -6.234      0.000      -1.427      -0.744\n",
       "Fare             0.0010      0.002      0.502      0.616      -0.003       0.005\n",
       "Age             -0.0276      0.009     -3.182      0.001      -0.045      -0.011\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_report.statsmodels_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
